{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4M726ZYPJA2m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b6a2d69-d805-4d22-b0fc-dfed6ea5e77b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stopwords downloaded successfully!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Download the list of common words to remove\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "print(\"Stopwords downloaded successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Import all the toolboxes we need\n",
        "import numpy as np\n",
        "import re\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "print(\"All libraries imported!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9PZCsMRyKnK",
        "outputId": "436bed43-f88e-4c3a-ce5b-d3589dda2f33"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All libraries imported!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Load the movie review data\n",
        "top_words = 5000\n",
        "print(\"Loading IMDB dataset... This might take a second.\")\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)\n",
        "\n",
        "# Let's see what we got\n",
        "print(f\"Number of training reviews: {len(X_train)}\")\n",
        "print(f\"Number of test reviews: {len(X_test)}\")\n",
        "print(f\"First training review label: {y_train[0]} (1 = Positive, 0 = Negative)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2WeKkCCzEgx",
        "outputId": "f4daea2f-9dc8-4221-e011-23026bf09a1f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading IMDB dataset... This might take a second.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "Number of training reviews: 25000\n",
            "Number of test reviews: 25000\n",
            "First training review label: 1 (1 = Positive, 0 = Negative)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Decode the numbers back into words\n",
        "word_index = imdb.get_word_index()\n",
        "reverse_word_index = {index: word for word, index in word_index.items()}\n",
        "\n",
        "# Function to decode a review\n",
        "def decode_review(encoded_review):\n",
        "    return ' '.join([reverse_word_index.get(i - 3, '?') for i in encoded_review])\n",
        "\n",
        "# Let's decode a few to see how it works\n",
        "print(\"Decoded Review Example:\")\n",
        "print(decode_review(X_train[0]))\n",
        "print(f\"\\nThis review's sentiment is: {'Positive' if y_train[0] == 1 else 'Negative'}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLBzkxn8z_8w",
        "outputId": "ecb00146-d87c-46fa-ea83-f0c3038bf607"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "\u001b[1m1641221/1641221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "Decoded Review Example:\n",
            "? this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the fly ? was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little ? that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big ? for the whole film but these children are amazing and should be ? for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was ? with us all\n",
            "\n",
            "This review's sentiment is: Positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Take a smaller sample of 1000 reviews\n",
        "num_reviews = 1000\n",
        "\n",
        "# Decode the reviews into text\n",
        "train_reviews = [decode_review(review) for review in X_train[:num_reviews]]\n",
        "train_sentiments = y_train[:num_reviews]\n",
        "\n",
        "test_reviews = [decode_review(review) for review in X_test[:num_reviews]]\n",
        "test_sentiments = y_test[:num_reviews]\n",
        "\n",
        "# Combine them into one big list\n",
        "all_reviews = train_reviews + test_reviews\n",
        "all_sentiments = np.concatenate([train_sentiments, test_sentiments])\n",
        "\n",
        "print(f\"Total reviews to analyze: {len(all_reviews)}\")\n",
        "print(f\"Total sentiments/scores: {len(all_sentiments)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoO4dzYT0zj-",
        "outputId": "097ff9df-1a80-43a3-9c0b-a6d94350228b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total reviews to analyze: 2000\n",
            "Total sentiments/scores: 2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Clean the text data (lowercase, remove junk, remove stopwords)\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # 1. Convert to lowercase\n",
        "    text = text.lower()\n",
        "    # 2. Remove special characters and numbers\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    # 3. Remove stopwords\n",
        "    words = text.split()\n",
        "    filtered_words = [word for word in words if word not in stop_words and len(word) > 1]\n",
        "    # 4. Join the words back into a single string\n",
        "    return ' '.join(filtered_words)\n",
        "\n",
        "# Let's test it on one review first!\n",
        "sample_review = \"This is a GREAT movie!!! It's full of awesome, fun, and exciting scenes.\"\n",
        "print(\"Original Text:\", sample_review)\n",
        "print(\"\\nPreprocessed Text:\", preprocess_text(sample_review))\n",
        "\n",
        "# Now, clean ALL our reviews (this will take a moment)\n",
        "print(\"\\nStarting to preprocess all reviews...\")\n",
        "processed_reviews = [preprocess_text(review) for review in all_reviews]\n",
        "print(\"Preprocessing complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXNWLJ6K1P6V",
        "outputId": "3c6d6689-4dc5-4214-eac6-60fdf826efc0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text: This is a GREAT movie!!! It's full of awesome, fun, and exciting scenes.\n",
            "\n",
            "Preprocessed Text: great movie full awesome fun exciting scenes\n",
            "\n",
            "Starting to preprocess all reviews...\n",
            "Preprocessing complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: Convert text to numbers\n",
        "vectorizer = CountVectorizer(max_features=3000)\n",
        "\n",
        "# Fit the vectorizer to our text and transform the text into numbers\n",
        "print(\"Converting text to numbers...\")\n",
        "X = vectorizer.fit_transform(processed_reviews).toarray()\n",
        "y = all_sentiments\n",
        "\n",
        "print(f\"Shape of our numerical data: {X.shape}\")\n",
        "print(\"Text has been successfully converted to numbers!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKayEl1F1mpB",
        "outputId": "59bcf8cf-912a-4955-9627-10726b20e1eb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting text to numbers...\n",
            "Shape of our numerical data: (2000, 3000)\n",
            "Text has been successfully converted to numbers!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 8: Split the data and train the model\n",
        "# Split the data: 80% for training, 20% for testing\n",
        "X_train_final, X_test_final, y_train_final, y_test_final = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Training samples: {X_train_final.shape[0]}\")\n",
        "print(f\"Testing samples: {X_test_final.shape[0]}\")\n",
        "\n",
        "# Create and train the model\n",
        "print(\"Training the Logistic Regression model...\")\n",
        "model = LogisticRegression(random_state=42, max_iter=200)\n",
        "model.fit(X_train_final, y_train_final)\n",
        "print(\"Model training complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aCrXAjI2H0m",
        "outputId": "32d045e7-545b-4aec-9abf-28ae07c48d58"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training samples: 1600\n",
            "Testing samples: 400\n",
            "Training the Logistic Regression model...\n",
            "Model training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 9: See how good the model is\n",
        "# Use the trained model to make predictions on the test set\n",
        "y_pred = model.predict(X_test_final)\n",
        "\n",
        "# Calculate how good the predictions are\n",
        "accuracy = accuracy_score(y_test_final, y_pred)\n",
        "precision = precision_score(y_test_final, y_pred)\n",
        "recall = recall_score(y_test_final, y_pred)\n",
        "\n",
        "print(\"\\n--- How Did Our Model Do? ---\")\n",
        "print(f\"Accuracy:  {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall:    {recall:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbwZ4frC2gsj",
        "outputId": "cf14e1c9-33c2-4212-963d-e2df4c45b3be"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- How Did Our Model Do? ---\n",
            "Accuracy:  0.8275 (82.75%)\n",
            "Precision: 0.8434\n",
            "Recall:    0.8146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 10: Test with your own words!\n",
        "# Function to predict any new review\n",
        "def predict_sentiment(new_review):\n",
        "    processed_review = preprocess_text(new_review)\n",
        "    vectorized_review = vectorizer.transform([processed_review])\n",
        "    prediction = model.predict(vectorized_review)\n",
        "    sentiment = \"Positive\" if prediction[0] == 1 else \"Negative\"\n",
        "    print(f\"Review: '{new_review}'\")\n",
        "    print(f\"Predicted Sentiment: {sentiment}\\n\")\n",
        "\n",
        "# Test with some examples\n",
        "print(\"--- Testing With Custom Reviews ---\")\n",
        "predict_sentiment(\"This movie was absolutely wonderful. The story was heartwarming and the acting was brilliant.\")\n",
        "predict_sentiment(\"I hated every minute of this film. It was boring, long, and poorly acted. A complete waste of time.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HorOWVJz28o3",
        "outputId": "65bc849b-17a5-4cd4-fff5-250bca2bb217"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Testing With Custom Reviews ---\n",
            "Review: 'This movie was absolutely wonderful. The story was heartwarming and the acting was brilliant.'\n",
            "Predicted Sentiment: Positive\n",
            "\n",
            "Review: 'I hated every minute of this film. It was boring, long, and poorly acted. A complete waste of time.'\n",
            "Predicted Sentiment: Negative\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DIpBz9VU3Zvi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}